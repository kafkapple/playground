{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix #classification_report\n",
    "import itertools  # for confusion matrix plot\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import cv2\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))      \n",
    "class_label = ['background', 'body','nose', 'tail']\n",
    "n_class = len(class_label)\n",
    "target_size = 40\n",
    "## model load\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 40, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 40, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 40, 40, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 40, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_1 (Spatial (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 40, 40, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 40, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_4 (Spatial (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 20, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 20, 64)        256       \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_2 (Spatial (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_3 (Spatial (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 6404      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 184,388\n",
      "Trainable params: 183,876\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path = '/Data/mice_processed/ak_mice.h5'\n",
    "model=load_model(model_path)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 40, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 40, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 40, 40, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 40, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_1 (Spatial (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 40, 40, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 40, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_4 (Spatial (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 20, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 20, 64)        256       \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_2 (Spatial (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_3 (Spatial (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 6404      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 361,732\n",
      "Trainable params: 183,876\n",
      "Non-trainable params: 177,856\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:479: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "# transfer learning\n",
    "count = 0\n",
    "for layer in model.layers[0:17]:\n",
    "    count+=1\n",
    "    layer.trainable = False\n",
    "print(count)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#import plot as pl\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))      \n",
    "class_label = ['background', 'body','nose', 'tail']\n",
    "n_class = len(class_label)\n",
    "target_size = 40\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "data_path ='/Data/mice_split'    \n",
    "    \n",
    "\n",
    "def preprocess_img(img):    \n",
    "    img=img.astype(np.uint8) # this is to match keras type? but uint8 might be more universal\n",
    "    img = clahe.apply(img) \n",
    "    img = img/255.  # normalize\n",
    "    img = np.reshape(img, (target_size,target_size,1))    \n",
    "    return img\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_acc', min_delta = 0.001, patience = 20, \n",
    "                               verbose = 1, mode = 'max')\n",
    "\n",
    "## Fit generator with augmentation\n",
    "\n",
    "def gen_train(model, data_path=data_path):     \n",
    "    train_datagen = ImageDataGenerator(\n",
    "               \n",
    "                rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                # randomly shift images horizontally (fraction of total width)\n",
    "                # set mode for filling points outside the input boundaries\n",
    "                fill_mode='nearest',\n",
    "                cval=0.,  # value used for fill_mode = \"constant\"\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=True,  # randomly flip images\n",
    "                # set rescaling factor (applied before any other transformation)\n",
    "                #rescale=1./255,\n",
    "                # set function that will be applied on each input\n",
    "                preprocessing_function=preprocess_img,\n",
    "                # image data format, either \"channels_first\" or \"channels_last\"\n",
    "                data_format=None, \n",
    "                # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "                validation_split=0)\n",
    "        \n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_img)#rescale=1./255)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            data_path+'/train/', shuffle=True,\n",
    "            target_size=(target_size, target_size),\n",
    "            #batch_size=batch_size, \n",
    "            color_mode = 'grayscale',\n",
    "            class_mode='categorical') #,  save_to_dir = data_path+'aug', save_prefix='aug_',) # option is for monitoring data augmentation\n",
    "    \n",
    "    val_generator = test_datagen.flow_from_directory(\n",
    "            data_path+'/validation/', shuffle=True,\n",
    "            target_size=(target_size, target_size),\n",
    "            #batch_size=batch_size, \n",
    "            color_mode = 'grayscale',\n",
    "            class_mode='categorical') #,  save_to_dir = data_path+'aug', save_prefix='aug_',) # option is for monitoring data augmentation\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "            data_path+'/test/', shuffle=False,\n",
    "            target_size=(target_size, target_size),\n",
    "            #batch_size=batch_size, \n",
    "            color_mode = 'grayscale',\n",
    "            class_mode='categorical') #,  save_to_dir = data_path+'aug', save_prefix='aug_',) # option is for monitoring data augmentation\n",
    "    \n",
    "    \n",
    "    hist = model.fit_generator(\n",
    "            train_generator,\n",
    "            #steps_per_epoch=30,\n",
    "            epochs=epochs, verbose=1,\n",
    "            validation_data=val_generator,\n",
    "            #validation_steps=10,\n",
    "            callbacks = [early_stopping])\n",
    "    \n",
    "    return hist, test_generator\n",
    "\n",
    "### evaluation result for generator / flow from dir\n",
    "def gen_eval(model, test_gen):\n",
    "    pred = model.predict_generator(test_gen)\n",
    "    \n",
    "    y_true = test_gen.classes\n",
    "    y_pred = np.argmax(pred,axis=1)\n",
    "\n",
    "    confusion_result = confusion_matrix(y_true, y_pred)\n",
    "    pl.plot_confusion_matrix(confusion_result, classes = class_label, normalize = True, title = 'Confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 images belonging to 4 classes.\n",
      "Found 96 images belonging to 4 classes.\n",
      "Found 96 images belonging to 4 classes.\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 6s 662ms/step - loss: 0.4100 - acc: 0.8715 - val_loss: 0.3871 - val_acc: 0.8958\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 6s 613ms/step - loss: 0.3606 - acc: 0.8438 - val_loss: 0.4118 - val_acc: 0.8854\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 5s 590ms/step - loss: 0.4022 - acc: 0.8264 - val_loss: 0.4105 - val_acc: 0.8854\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 5s 583ms/step - loss: 0.4196 - acc: 0.8264 - val_loss: 0.4089 - val_acc: 0.8854\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 5s 597ms/step - loss: 0.3466 - acc: 0.8715 - val_loss: 0.4113 - val_acc: 0.8854\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 5s 579ms/step - loss: 0.3869 - acc: 0.8333 - val_loss: 0.4109 - val_acc: 0.8854\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 5s 585ms/step - loss: 0.3535 - acc: 0.8507 - val_loss: 0.4134 - val_acc: 0.8854\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 5s 585ms/step - loss: 0.4173 - acc: 0.8229 - val_loss: 0.4138 - val_acc: 0.8854\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 5s 602ms/step - loss: 0.3857 - acc: 0.8438 - val_loss: 0.4142 - val_acc: 0.8854\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 5s 579ms/step - loss: 0.3537 - acc: 0.8472 - val_loss: 0.4145 - val_acc: 0.8750\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 5s 587ms/step - loss: 0.4096 - acc: 0.8438 - val_loss: 0.4159 - val_acc: 0.8750\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 5s 596ms/step - loss: 0.3738 - acc: 0.8438 - val_loss: 0.4164 - val_acc: 0.8750\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 5s 581ms/step - loss: 0.4319 - acc: 0.8403 - val_loss: 0.4141 - val_acc: 0.8750\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 5s 583ms/step - loss: 0.3702 - acc: 0.8368 - val_loss: 0.4146 - val_acc: 0.8750\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 5s 605ms/step - loss: 0.3636 - acc: 0.8576 - val_loss: 0.4150 - val_acc: 0.8750\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 5s 578ms/step - loss: 0.3560 - acc: 0.8611 - val_loss: 0.4140 - val_acc: 0.8854\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 5s 598ms/step - loss: 0.4264 - acc: 0.8299 - val_loss: 0.4145 - val_acc: 0.8854\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 5s 589ms/step - loss: 0.3376 - acc: 0.8681 - val_loss: 0.4137 - val_acc: 0.8854\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 5s 578ms/step - loss: 0.4242 - acc: 0.8438 - val_loss: 0.4154 - val_acc: 0.8854\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 6s 614ms/step - loss: 0.4200 - acc: 0.8264 - val_loss: 0.4164 - val_acc: 0.8854\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 5s 597ms/step - loss: 0.4264 - acc: 0.8299 - val_loss: 0.4164 - val_acc: 0.8854\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss = categorical_crossentropy,\n",
    "              optimizer = Adam(lr = 0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-7),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "hist, test_gen = gen_train(model, data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\github\\\\test'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('mice_transfer.h5')\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
